{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJg5fOXn60nH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/CV/Brain Tumor Detection Dataset/brain_tumor_dataset'"
      ],
      "metadata": {
        "id": "8IpSbqGehQ5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of image files\n",
        "yes_tumor_files = [os.path.join(dataset_path, 'YES', filename) for filename in os.listdir(os.path.join(dataset_path, 'YES'))]\n",
        "no_tumor_files = [os.path.join(dataset_path, 'NO', filename) for filename in os.listdir(os.path.join(dataset_path, 'NO'))]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ILOrlhoXhRh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = 224, 224\n",
        "\n",
        "# Create a list to store images and labels\n",
        "images = []\n",
        "labels = []\n"
      ],
      "metadata": {
        "id": "eVR1-Pu1hZsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images with tumors ('YES')\n",
        "for file_path in yes_tumor_files:\n",
        "    img = tf.keras.preprocessing.image.load_img(file_path, target_size=(img_height, img_width))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    images.append(img_array)\n",
        "    labels.append(1)  # 1 for 'YES'"
      ],
      "metadata": {
        "id": "Ott9-3awkR8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_path in no_tumor_files:\n",
        "    img = tf.keras.preprocessing.image.load_img(file_path, target_size=(img_height, img_width))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    images.append(img_array)\n",
        "    labels.append(0)  # 0 for 'NO'"
      ],
      "metadata": {
        "id": "WDXyGHLRqK0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "#train test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "hO54XDzaqcY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))  # Dropout layer for regularization\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "832s7CptqnWc",
        "outputId": "705653d0-265e-4d2b-82ec-621bf9ccfa1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nxGEwGuTqsIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "train_datagen.fit(X_train)\n"
      ],
      "metadata": {
        "id": "5ICdtbdsqwqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_datagen.flow(X_train, y_train, batch_size=32), epochs=176, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXKFS9KNqycd",
        "outputId": "071db7b4-6da2-40cb-c2ee-3ea68c8eb556"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5s/step - accuracy: 0.6013 - loss: 0.8304 - val_accuracy: 0.7843 - val_loss: 20.3774\n",
            "Epoch 2/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.7218 - loss: 0.6034 - val_accuracy: 0.7255 - val_loss: 49.8594\n",
            "Epoch 3/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.7746 - loss: 0.5569 - val_accuracy: 0.7255 - val_loss: 53.6548\n",
            "Epoch 4/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.7853 - loss: 0.5553 - val_accuracy: 0.6863 - val_loss: 80.0862\n",
            "Epoch 5/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.7606 - loss: 0.5187 - val_accuracy: 0.6667 - val_loss: 57.2435\n",
            "Epoch 6/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3s/step - accuracy: 0.6500 - loss: 0.6611 - val_accuracy: 0.7451 - val_loss: 44.3676\n",
            "Epoch 7/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.7930 - loss: 0.5416 - val_accuracy: 0.7451 - val_loss: 56.0258\n",
            "Epoch 8/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.7928 - loss: 0.4937 - val_accuracy: 0.7451 - val_loss: 86.7929\n",
            "Epoch 9/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.7813 - loss: 0.4840 - val_accuracy: 0.7451 - val_loss: 54.6965\n",
            "Epoch 10/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.7332 - loss: 0.5823 - val_accuracy: 0.7451 - val_loss: 63.0041\n",
            "Epoch 11/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.7587 - loss: 0.4986 - val_accuracy: 0.7647 - val_loss: 80.2031\n",
            "Epoch 12/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.8121 - loss: 0.4712 - val_accuracy: 0.7255 - val_loss: 46.9084\n",
            "Epoch 13/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - accuracy: 0.7227 - loss: 0.5372 - val_accuracy: 0.7255 - val_loss: 52.8660\n",
            "Epoch 14/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.7007 - loss: 0.5750 - val_accuracy: 0.7059 - val_loss: 63.1686\n",
            "Epoch 15/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.7816 - loss: 0.4399 - val_accuracy: 0.7255 - val_loss: 82.7853\n",
            "Epoch 16/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.7877 - loss: 0.4341 - val_accuracy: 0.7451 - val_loss: 54.1730\n",
            "Epoch 17/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.8643 - loss: 0.3836 - val_accuracy: 0.7451 - val_loss: 57.5494\n",
            "Epoch 18/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.8298 - loss: 0.4040 - val_accuracy: 0.7647 - val_loss: 75.2248\n",
            "Epoch 19/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.8427 - loss: 0.4362 - val_accuracy: 0.7451 - val_loss: 69.2860\n",
            "Epoch 20/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.8775 - loss: 0.3672 - val_accuracy: 0.7451 - val_loss: 91.4161\n",
            "Epoch 21/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.8377 - loss: 0.3959 - val_accuracy: 0.7647 - val_loss: 74.9614\n",
            "Epoch 22/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.8734 - loss: 0.3522 - val_accuracy: 0.7843 - val_loss: 81.4508\n",
            "Epoch 23/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.8637 - loss: 0.2987 - val_accuracy: 0.7451 - val_loss: 78.7382\n",
            "Epoch 24/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.8935 - loss: 0.2837 - val_accuracy: 0.7451 - val_loss: 102.5370\n",
            "Epoch 25/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.8181 - loss: 0.3696 - val_accuracy: 0.8039 - val_loss: 93.7496\n",
            "Epoch 26/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.8496 - loss: 0.3767 - val_accuracy: 0.7451 - val_loss: 64.1048\n",
            "Epoch 27/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.8720 - loss: 0.3349 - val_accuracy: 0.7647 - val_loss: 107.2352\n",
            "Epoch 28/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.8467 - loss: 0.3529 - val_accuracy: 0.7451 - val_loss: 112.5332\n",
            "Epoch 29/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.8968 - loss: 0.2618 - val_accuracy: 0.7843 - val_loss: 121.8848\n",
            "Epoch 30/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.8811 - loss: 0.3322 - val_accuracy: 0.8431 - val_loss: 90.0029\n",
            "Epoch 31/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.8665 - loss: 0.3004 - val_accuracy: 0.8235 - val_loss: 98.6189\n",
            "Epoch 32/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9355 - loss: 0.2383 - val_accuracy: 0.8235 - val_loss: 144.5900\n",
            "Epoch 33/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4s/step - accuracy: 0.8715 - loss: 0.2741 - val_accuracy: 0.8039 - val_loss: 135.0837\n",
            "Epoch 34/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.8696 - loss: 0.2778 - val_accuracy: 0.7647 - val_loss: 121.3267\n",
            "Epoch 35/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.8879 - loss: 0.2639 - val_accuracy: 0.7647 - val_loss: 162.8057\n",
            "Epoch 36/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.8891 - loss: 0.2850 - val_accuracy: 0.7843 - val_loss: 131.2166\n",
            "Epoch 37/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9268 - loss: 0.2393 - val_accuracy: 0.7647 - val_loss: 125.7955\n",
            "Epoch 38/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4s/step - accuracy: 0.9209 - loss: 0.2474 - val_accuracy: 0.7647 - val_loss: 124.8151\n",
            "Epoch 39/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.9576 - loss: 0.1817 - val_accuracy: 0.7843 - val_loss: 167.6647\n",
            "Epoch 40/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9267 - loss: 0.2058 - val_accuracy: 0.7843 - val_loss: 173.5581\n",
            "Epoch 41/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9249 - loss: 0.1791 - val_accuracy: 0.8039 - val_loss: 163.7395\n",
            "Epoch 42/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.9158 - loss: 0.1489 - val_accuracy: 0.7647 - val_loss: 161.7955\n",
            "Epoch 43/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4s/step - accuracy: 0.8911 - loss: 0.2787 - val_accuracy: 0.7451 - val_loss: 133.2117\n",
            "Epoch 44/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9483 - loss: 0.1909 - val_accuracy: 0.7843 - val_loss: 148.7549\n",
            "Epoch 45/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9281 - loss: 0.1582 - val_accuracy: 0.8235 - val_loss: 160.5549\n",
            "Epoch 46/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5s/step - accuracy: 0.9611 - loss: 0.1198 - val_accuracy: 0.8039 - val_loss: 185.6425\n",
            "Epoch 47/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9465 - loss: 0.1508 - val_accuracy: 0.8235 - val_loss: 193.5320\n",
            "Epoch 48/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4s/step - accuracy: 0.9491 - loss: 0.1286 - val_accuracy: 0.8235 - val_loss: 222.1702\n",
            "Epoch 49/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3s/step - accuracy: 0.9507 - loss: 0.1757 - val_accuracy: 0.8039 - val_loss: 243.8531\n",
            "Epoch 50/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9295 - loss: 0.1566 - val_accuracy: 0.8039 - val_loss: 198.8501\n",
            "Epoch 51/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.9723 - loss: 0.1295 - val_accuracy: 0.7843 - val_loss: 201.0365\n",
            "Epoch 52/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9484 - loss: 0.1634 - val_accuracy: 0.7843 - val_loss: 175.0515\n",
            "Epoch 53/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.9532 - loss: 0.1205 - val_accuracy: 0.8039 - val_loss: 208.7928\n",
            "Epoch 54/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9751 - loss: 0.0881 - val_accuracy: 0.7647 - val_loss: 220.2885\n",
            "Epoch 55/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9772 - loss: 0.0646 - val_accuracy: 0.7647 - val_loss: 227.6814\n",
            "Epoch 56/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9120 - loss: 0.1642 - val_accuracy: 0.7451 - val_loss: 185.8830\n",
            "Epoch 57/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.9527 - loss: 0.1494 - val_accuracy: 0.7647 - val_loss: 196.9989\n",
            "Epoch 58/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9528 - loss: 0.1269 - val_accuracy: 0.6667 - val_loss: 334.0110\n",
            "Epoch 59/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.9361 - loss: 0.2024 - val_accuracy: 0.7451 - val_loss: 187.7129\n",
            "Epoch 60/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9181 - loss: 0.1864 - val_accuracy: 0.7647 - val_loss: 225.6112\n",
            "Epoch 61/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9551 - loss: 0.1252 - val_accuracy: 0.7255 - val_loss: 285.6292\n",
            "Epoch 62/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9350 - loss: 0.1663 - val_accuracy: 0.7059 - val_loss: 219.3327\n",
            "Epoch 63/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9539 - loss: 0.1119 - val_accuracy: 0.7451 - val_loss: 250.1967\n",
            "Epoch 64/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.8978 - loss: 0.2836 - val_accuracy: 0.6667 - val_loss: 249.6192\n",
            "Epoch 65/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9681 - loss: 0.1132 - val_accuracy: 0.7647 - val_loss: 235.0707\n",
            "Epoch 66/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.9922 - loss: 0.0587 - val_accuracy: 0.7451 - val_loss: 288.3791\n",
            "Epoch 67/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9573 - loss: 0.1064 - val_accuracy: 0.7451 - val_loss: 312.9929\n",
            "Epoch 68/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9423 - loss: 0.1629 - val_accuracy: 0.6471 - val_loss: 351.4203\n",
            "Epoch 69/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9645 - loss: 0.1083 - val_accuracy: 0.7647 - val_loss: 240.7026\n",
            "Epoch 70/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.9303 - loss: 0.1261 - val_accuracy: 0.7451 - val_loss: 335.2255\n",
            "Epoch 71/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9157 - loss: 0.1782 - val_accuracy: 0.7451 - val_loss: 260.2599\n",
            "Epoch 72/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.9656 - loss: 0.1141 - val_accuracy: 0.7843 - val_loss: 272.4303\n",
            "Epoch 73/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9956 - loss: 0.0462 - val_accuracy: 0.7843 - val_loss: 266.9111\n",
            "Epoch 74/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9895 - loss: 0.0749 - val_accuracy: 0.8039 - val_loss: 262.5963\n",
            "Epoch 75/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4s/step - accuracy: 0.9895 - loss: 0.0488 - val_accuracy: 0.8039 - val_loss: 273.1500\n",
            "Epoch 76/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9561 - loss: 0.0907 - val_accuracy: 0.7843 - val_loss: 280.7266\n",
            "Epoch 77/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.9715 - loss: 0.0644 - val_accuracy: 0.7255 - val_loss: 276.6075\n",
            "Epoch 78/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9842 - loss: 0.0561 - val_accuracy: 0.8039 - val_loss: 282.1322\n",
            "Epoch 79/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9797 - loss: 0.0530 - val_accuracy: 0.8039 - val_loss: 288.3909\n",
            "Epoch 80/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9900 - loss: 0.0471 - val_accuracy: 0.7647 - val_loss: 301.6374\n",
            "Epoch 81/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9755 - loss: 0.0719 - val_accuracy: 0.7647 - val_loss: 334.4012\n",
            "Epoch 82/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4s/step - accuracy: 0.9826 - loss: 0.0648 - val_accuracy: 0.7647 - val_loss: 346.8034\n",
            "Epoch 83/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9947 - loss: 0.0159 - val_accuracy: 0.8039 - val_loss: 373.4875\n",
            "Epoch 84/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9882 - loss: 0.0467 - val_accuracy: 0.7843 - val_loss: 399.2168\n",
            "Epoch 85/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.9768 - loss: 0.0603 - val_accuracy: 0.7255 - val_loss: 341.5669\n",
            "Epoch 86/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9660 - loss: 0.1345 - val_accuracy: 0.7451 - val_loss: 276.6974\n",
            "Epoch 87/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9864 - loss: 0.0530 - val_accuracy: 0.7647 - val_loss: 326.6612\n",
            "Epoch 88/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5s/step - accuracy: 0.9749 - loss: 0.0559 - val_accuracy: 0.7647 - val_loss: 300.7547\n",
            "Epoch 89/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.9728 - loss: 0.0580 - val_accuracy: 0.7059 - val_loss: 342.6049\n",
            "Epoch 90/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9694 - loss: 0.0642 - val_accuracy: 0.8039 - val_loss: 330.7105\n",
            "Epoch 91/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.9860 - loss: 0.0349 - val_accuracy: 0.7647 - val_loss: 348.4313\n",
            "Epoch 92/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.9898 - loss: 0.0318 - val_accuracy: 0.8039 - val_loss: 319.8068\n",
            "Epoch 93/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9520 - loss: 0.1217 - val_accuracy: 0.7451 - val_loss: 314.2902\n",
            "Epoch 94/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.9881 - loss: 0.0411 - val_accuracy: 0.7843 - val_loss: 345.3696\n",
            "Epoch 95/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9910 - loss: 0.0388 - val_accuracy: 0.7647 - val_loss: 383.3752\n",
            "Epoch 96/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.9819 - loss: 0.0259 - val_accuracy: 0.7647 - val_loss: 373.1253\n",
            "Epoch 97/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9771 - loss: 0.0951 - val_accuracy: 0.7451 - val_loss: 351.1525\n",
            "Epoch 98/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.9816 - loss: 0.0694 - val_accuracy: 0.7647 - val_loss: 345.8253\n",
            "Epoch 99/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9940 - loss: 0.0177 - val_accuracy: 0.7647 - val_loss: 355.2336\n",
            "Epoch 100/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9959 - loss: 0.0213 - val_accuracy: 0.8235 - val_loss: 400.4770\n",
            "Epoch 101/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9856 - loss: 0.0372 - val_accuracy: 0.7647 - val_loss: 372.5834\n",
            "Epoch 102/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9821 - loss: 0.0546 - val_accuracy: 0.7843 - val_loss: 346.2377\n",
            "Epoch 103/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9948 - loss: 0.0331 - val_accuracy: 0.7451 - val_loss: 382.8778\n",
            "Epoch 104/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9890 - loss: 0.0604 - val_accuracy: 0.7647 - val_loss: 369.2493\n",
            "Epoch 105/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9880 - loss: 0.0320 - val_accuracy: 0.7451 - val_loss: 343.6449\n",
            "Epoch 106/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4s/step - accuracy: 0.9620 - loss: 0.0529 - val_accuracy: 0.7451 - val_loss: 351.0463\n",
            "Epoch 107/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9826 - loss: 0.0461 - val_accuracy: 0.7451 - val_loss: 392.6170\n",
            "Epoch 108/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9919 - loss: 0.0246 - val_accuracy: 0.7451 - val_loss: 458.2410\n",
            "Epoch 109/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9615 - loss: 0.1023 - val_accuracy: 0.7451 - val_loss: 428.6399\n",
            "Epoch 110/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9962 - loss: 0.0224 - val_accuracy: 0.7451 - val_loss: 413.9630\n",
            "Epoch 111/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.9971 - loss: 0.0178 - val_accuracy: 0.8039 - val_loss: 463.5145\n",
            "Epoch 112/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.9891 - loss: 0.0486 - val_accuracy: 0.7647 - val_loss: 448.1496\n",
            "Epoch 113/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9961 - loss: 0.0226 - val_accuracy: 0.7843 - val_loss: 451.3582\n",
            "Epoch 114/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.7647 - val_loss: 457.9622\n",
            "Epoch 115/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9980 - loss: 0.0056 - val_accuracy: 0.7647 - val_loss: 479.5201\n",
            "Epoch 116/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9803 - loss: 0.0324 - val_accuracy: 0.7451 - val_loss: 451.8920\n",
            "Epoch 117/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9638 - loss: 0.0754 - val_accuracy: 0.7647 - val_loss: 407.2048\n",
            "Epoch 118/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9894 - loss: 0.0206 - val_accuracy: 0.7843 - val_loss: 408.3126\n",
            "Epoch 119/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9929 - loss: 0.0242 - val_accuracy: 0.7647 - val_loss: 453.1515\n",
            "Epoch 120/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9950 - loss: 0.0228 - val_accuracy: 0.7451 - val_loss: 481.2242\n",
            "Epoch 121/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9898 - loss: 0.0219 - val_accuracy: 0.7255 - val_loss: 508.0497\n",
            "Epoch 122/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9917 - loss: 0.0123 - val_accuracy: 0.7059 - val_loss: 548.5917\n",
            "Epoch 123/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9988 - loss: 0.0124 - val_accuracy: 0.7647 - val_loss: 544.0511\n",
            "Epoch 124/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9808 - loss: 0.0558 - val_accuracy: 0.7647 - val_loss: 460.4877\n",
            "Epoch 125/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.6471 - val_loss: 452.2569\n",
            "Epoch 126/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9829 - loss: 0.0325 - val_accuracy: 0.6667 - val_loss: 430.5541\n",
            "Epoch 127/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4s/step - accuracy: 0.9959 - loss: 0.0267 - val_accuracy: 0.7255 - val_loss: 382.9228\n",
            "Epoch 128/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9694 - loss: 0.0580 - val_accuracy: 0.7843 - val_loss: 422.2943\n",
            "Epoch 129/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9903 - loss: 0.0318 - val_accuracy: 0.7843 - val_loss: 465.3061\n",
            "Epoch 130/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.9927 - loss: 0.0212 - val_accuracy: 0.7451 - val_loss: 501.0189\n",
            "Epoch 131/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4s/step - accuracy: 0.9849 - loss: 0.0351 - val_accuracy: 0.7647 - val_loss: 471.4939\n",
            "Epoch 132/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9842 - loss: 0.0337 - val_accuracy: 0.7255 - val_loss: 480.4319\n",
            "Epoch 133/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.9973 - loss: 0.0193 - val_accuracy: 0.7059 - val_loss: 468.7232\n",
            "Epoch 134/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.9980 - loss: 0.0129 - val_accuracy: 0.7451 - val_loss: 481.2210\n",
            "Epoch 135/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 4s/step - accuracy: 0.9929 - loss: 0.0182 - val_accuracy: 0.6863 - val_loss: 518.6259\n",
            "Epoch 136/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.7647 - val_loss: 523.2755\n",
            "Epoch 137/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9901 - loss: 0.0298 - val_accuracy: 0.7255 - val_loss: 538.0580\n",
            "Epoch 138/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.9739 - loss: 0.0363 - val_accuracy: 0.7255 - val_loss: 494.7512\n",
            "Epoch 139/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7255 - val_loss: 475.2382\n",
            "Epoch 140/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4s/step - accuracy: 0.9931 - loss: 0.0122 - val_accuracy: 0.7255 - val_loss: 457.3210\n",
            "Epoch 141/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.9873 - loss: 0.0573 - val_accuracy: 0.7059 - val_loss: 471.5200\n",
            "Epoch 142/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9943 - loss: 0.0097 - val_accuracy: 0.7451 - val_loss: 460.1031\n",
            "Epoch 143/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.7843 - val_loss: 463.3946\n",
            "Epoch 144/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.7843 - val_loss: 464.5587\n",
            "Epoch 145/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9780 - loss: 0.0594 - val_accuracy: 0.7059 - val_loss: 466.6756\n",
            "Epoch 146/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9932 - loss: 0.0224 - val_accuracy: 0.7059 - val_loss: 511.9649\n",
            "Epoch 147/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9973 - loss: 0.0158 - val_accuracy: 0.7451 - val_loss: 552.4538\n",
            "Epoch 148/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.9959 - loss: 0.0221 - val_accuracy: 0.7451 - val_loss: 567.0275\n",
            "Epoch 149/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.9712 - loss: 0.0696 - val_accuracy: 0.7255 - val_loss: 545.9395\n",
            "Epoch 150/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4s/step - accuracy: 0.9959 - loss: 0.0099 - val_accuracy: 0.7647 - val_loss: 516.8504\n",
            "Epoch 151/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.9913 - loss: 0.0360 - val_accuracy: 0.7647 - val_loss: 525.6443\n",
            "Epoch 152/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.9912 - loss: 0.0118 - val_accuracy: 0.7647 - val_loss: 512.5716\n",
            "Epoch 153/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.7647 - val_loss: 508.5999\n",
            "Epoch 154/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.7451 - val_loss: 538.6514\n",
            "Epoch 155/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.7451 - val_loss: 606.7187\n",
            "Epoch 156/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.9964 - loss: 0.0111 - val_accuracy: 0.7451 - val_loss: 631.4858\n",
            "Epoch 157/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.7255 - val_loss: 643.3328\n",
            "Epoch 158/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9980 - loss: 0.0073 - val_accuracy: 0.7255 - val_loss: 658.3809\n",
            "Epoch 159/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.7451 - val_loss: 644.1760\n",
            "Epoch 160/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7255 - val_loss: 652.4420\n",
            "Epoch 161/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9988 - loss: 0.0029 - val_accuracy: 0.7255 - val_loss: 675.0549\n",
            "Epoch 162/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9927 - loss: 0.0230 - val_accuracy: 0.7255 - val_loss: 618.2618\n",
            "Epoch 163/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9942 - loss: 0.0105 - val_accuracy: 0.7451 - val_loss: 592.5552\n",
            "Epoch 164/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.9930 - loss: 0.0073 - val_accuracy: 0.6863 - val_loss: 591.9498\n",
            "Epoch 165/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9780 - loss: 0.0339 - val_accuracy: 0.7255 - val_loss: 523.9457\n",
            "Epoch 166/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.9959 - loss: 0.0125 - val_accuracy: 0.7451 - val_loss: 502.2078\n",
            "Epoch 167/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9780 - loss: 0.0624 - val_accuracy: 0.7451 - val_loss: 514.2780\n",
            "Epoch 168/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.9788 - loss: 0.0421 - val_accuracy: 0.6667 - val_loss: 567.6344\n",
            "Epoch 169/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9980 - loss: 0.0134 - val_accuracy: 0.7255 - val_loss: 613.6203\n",
            "Epoch 170/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.7255 - val_loss: 665.6867\n",
            "Epoch 171/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9964 - loss: 0.0087 - val_accuracy: 0.7451 - val_loss: 650.6039\n",
            "Epoch 172/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.7647 - val_loss: 629.1453\n",
            "Epoch 173/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.7647 - val_loss: 645.5187\n",
            "Epoch 174/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.7647 - val_loss: 650.9061\n",
            "Epoch 175/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9988 - loss: 0.0020 - val_accuracy: 0.7647 - val_loss: 634.6533\n",
            "Epoch 176/176\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3s/step - accuracy: 0.9770 - loss: 0.0465 - val_accuracy: 0.7647 - val_loss: 577.0551\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2066989b80>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_val, y_val)\n",
        "print(f\"Test Accuracy: {test_acc}\")\n",
        "model.save(\"Binary Classification Tumor Detection Model.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xxr0jvplq15n",
        "outputId": "ae9f3409-b3e8-44cf-f77c-15754a4e5a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 473ms/step - accuracy: 0.7598 - loss: 592.1978\n",
            "Test Accuracy: 0.7647058963775635\n"
          ]
        }
      ]
    }
  ]
}